# ============================================================================ #
# ‚öôÔ∏è GENERAL CONFIGURATION FILE
# ---------------------------------------------------------------------------- #
# This file defines all key components for training and evaluating the SR model.
# Sections: Data, Model, Training, Architecture, Optimization, Scheduling, Logging
# ============================================================================ #


# ============================================================================ #
# üóÇÔ∏è DATA SETTINGS
# ---------------------------------------------------------------------------- #
Data:
  # Loader parameters
  train_batch_size: 12        # Batch size for training
  val_batch_size: 8           # Batch size for validation
  num_workers: 6              # Number of parallel workers for dataloader
  prefetch_factor: 2          # Samples prefetched per worker (2 is stable default)

  # Dataset configuration
  dataset_type: 'S2_6b'       # Choose dataset type: ['cv', 'SPOT6', 'S2_6b']


# ============================================================================ #
# üß† MODEL AND CHECKPOINT SETTINGS
# ---------------------------------------------------------------------------- #
Model:
  in_bands: 6                 # Number of input channels (e.g. RGB-NIR-SWIR etc.)
  continue_training: False    # Resume full training (PL checkpoint path or False)
  load_checkpoint: False      # Load weights only (path or False)


# ============================================================================ #
# üèãÔ∏è TRAINING CONFIGURATION
# ---------------------------------------------------------------------------- #
Training:
  # --- Pretraining and adversarial setup ---
  pretrain_g_only: True        # Train generator only for initial phase
  g_pretrain_steps: 10000     # Number of generator-only warmup steps
  adv_loss_ramp_steps: 5000   # Gradual adversarial weight ramp steps
  label_smoothing: True        # Discriminator target smoothing (1.0 ‚Üí 0.9)

  Losses:
    # --- GAN term ---
    adv_loss_beta: 1e-3        # Final adversarial loss weight after ramp-up
    adv_loss_schedule: 'sigmoid'  # Adversarial weight ramp type: ['linear', 'sigmoid']

    # --- Content loss components (GeneratorContentLoss) ---
    l1_weight: 1.0             # L1 loss over all bands
    sam_weight: 0.05           # Spectral Angle Mapper loss
    perceptual_weight: 0.1     # Perceptual similarity term weight
    perceptual_metric: 'vgg'   # ['vgg', 'lpips'] - LPIPS requires pip install lpips
    tv_weight: 0.0             # Total Variation regularization (optional)

    # --- Metric evaluation settings ---
    max_val: 1.0               # Peak value assumed by PSNR/SSIM after metric preprocessing
    ssim_win: 11               # SSIM window size (must be odd integer)


# ============================================================================ #
# üß© ARCHITECTURAL PARAMETERS
# ---------------------------------------------------------------------------- #
Generator:
  model_type: 'cgan'           # Block type: ['SRResNet', 'res', 'rcab', 'rrdb', 'lka', 'conditional_cgan'/'cgan']
  large_kernel_size: 9         # Kernel for head and tail conv layers
  small_kernel_size: 3         # Kernel for intermediate blocks
  n_channels: 96               # Number of feature channels (original 64)
  n_blocks: 32                 # Number of residual/attention blocks (original 16)
  scaling_factor: 8            # Upscaling factor (e.g., 2√ó, 4√ó, 8√ó)

Discriminator:
  model_type: 'standard'       # Discriminator architecture selector ['standard', 'patchgan']
  n_blocks: 8                  # Number of convolutional blocks / layers: ['standard': 8, 'patchgan': 3]

TruncatedVGG:
  i: 5                         # Layer indices for feature extraction
  j: 4


# ============================================================================ #
# üßÆ OPTIMIZATION SETTINGS
# ---------------------------------------------------------------------------- #
Optimizers:
  optim_g_lr: 1e-4             # Learning rate for Generator
  optim_d_lr: 1e-4             # Learning rate for Discriminator


# ============================================================================ #
# üìâ SCHEDULERS AND EARLY STOPPING
# ---------------------------------------------------------------------------- #
Schedulers:
  metric: 'val_metrics/l1'     # Metric monitored for both schedulers
  patience_g: 100              # Patience (epochs) for Generator LR scheduler
  patience_d: 100              # Patience (epochs) for Discriminator LR scheduler
  factor_g: 0.5                # LR reduction factor for Generator
  factor_d: 0.5                # LR reduction factor for Discriminator
  verbose: True                # Enable scheduler logging output


# ============================================================================ #
# üßæ LOGGING SETTINGS
# ---------------------------------------------------------------------------- #
Logging:
  num_val_images: 5            # Number of validation images logged per epoch
