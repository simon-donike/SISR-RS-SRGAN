# Getting started

This guide walks through installing dependencies, configuring datasets, and launching your first ESA OpenSR experiment. The stack
uses Python 3.10+, PyTorch Lightning, and Weights & Biases for experiment tracking.

## 1. Install the environment

1. **Create a virtual environment.**
   ```bash
   python -m venv .venv
   source .venv/bin/activate
   ```
2. **Install Python dependencies.**
   ```bash
   pip install -r requirements.txt
   ```
3. **Authenticate logging backends (optional but recommended).**
   * Run `wandb login` to capture metrics and images in your W&B workspace.
   * Start `tensorboard --logdir logs/` if you prefer local dashboards.

## 2. Gather training data

ESA OpenSR currently ships with dataset wrappers for Sentinel-2 SAFE archives and the SEN2NAIP worldwide dataset.

* **Sentinel-2 SAFE (6-band or 4-band).** Build a manifest JSON that lists the LR/HR pairs generated by your tiling pipeline. The
  sample configuration expects a file similar to `/data3/S2_20m/s2_safe_manifest_20m.json`.
* **SEN2NAIP worldwide.** Point the configuration to the root directory that contains the preprocessed train/val splits.

Refer to [Data](data.md) for dataset-specific requirements and how to plug in new sources.

## 3. Configure the experiment

Copy one of the provided YAML presets and edit it to match your setup:

```bash
cp configs/config_20m.yaml my_experiment.yaml
```

Update at least the following fields:

* `Data.dataset_type`: Choose `S2_6b`, `S2_4b`, or `SISR_WW`.
* `Generator.scaling_factor`: Set the desired upscaling (e.g., `4` or `8`).
* `Model.load_checkpoint`: Provide a path if you want to fine-tune an existing checkpoint.
* `Training.Losses.perceptual_metric`: Switch to `lpips` if you installed the optional dependency.

See [Configuration](configuration.md) for a full breakdown of available options.

## 4. Launch training

Run the training script with your customised config:

```bash
python train.py --config my_experiment.yaml
```

The script will:

1. Instantiate the `SRGAN_model` Lightning module from the YAML file.
2. Build the appropriate dataset pair and wrap it in a `LightningDataModule`.
3. Configure Weights & Biases and TensorBoard loggers alongside checkpointing and learning-rate monitoring callbacks.
4. Start alternating generator/discriminator optimisation according to your warm-start schedule.

Training resumes automatically if `Model.continue_training` points to a Lightning checkpoint.

## 5. Run validation or inference

* **Validation metrics** are logged at the end of each epoch, including L1, SAM, PSNR/SSIM (from the content loss helper), and
  discriminator statistics.
* **Qualitative monitoring** is available through Weights & Biases image panels when `Logging.num_val_images` is greater than zero.
* **Inference** on new low-resolution tiles can reuse the Lightning module:
  ```python
  from model.SRGAN import SRGAN_model
  model = SRGAN_model.load_from_checkpoint("path/to/checkpoint.ckpt")
  sr_tiles = model.predict_step(lr_tiles)
  ```
  The helper automatically normalises Sentinel-2 ranges, applies histogram matching, and denormalises outputs for easier
  comparison with the source imagery.

## 6. Next steps

* Explore alternative generator backbones such as RCAB or RRDB by changing `Generator.model_type`.
* Adjust adversarial warm-up with `Training.pretrain_g_only`, `g_pretrain_steps`, and `adv_loss_ramp_steps` if you observe
  instability.
* Integrate new datasets by extending the factory in `data/data_utils.py` and documenting them in [Data](data.md).
